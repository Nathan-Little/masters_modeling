{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the roster from masters.com. This includes amatuers, so we need to take those out. \n",
    "\n",
    "Source: https://www.masters.com/en_US/players/invitees_2020.html\n",
    "\n",
    "We copied and pasted the table into an excel sheet and did some initial cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = pd.read_excel('players.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_name(name):\n",
    "    '''Goes from `last, first` to `first last`\n",
    "        Also removes \"#\" from the name\n",
    "    '''\n",
    "    name = name.replace('#', \"\")\n",
    "    name_lst = name.split(',')\n",
    "    name_lst = [name.strip() for name in name_lst[::-1]]\n",
    "    return \" \".join(name_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_2020 = []\n",
    "for row in roster.itertuples(): \n",
    "    if \"*\" not in row.Name:\n",
    "        players_2020.append(reverse_name(row.Name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(players_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv('2020_players.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Tournment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get links to all of the tournements in the past 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link = \"https://www.espn.com/golf/schedule/_/season/\"\n",
    "main_links = [\n",
    "    'https://www.espn.com/golf/schedule/_/season/2010',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2011',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2012',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2013',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2014',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2015',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2016',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2017',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2018', \n",
    "    'https://www.espn.com/golf/schedule/_/season/2019',\n",
    "    'https://www.espn.com/golf/schedule/_/season/2020'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all tournement links from the table\n",
    "\n",
    "There are tournement links and player links. Tournement links do not have \"player\" in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournement_links = {}\n",
    "# For each year\n",
    "for link in main_links:\n",
    "    year = link.split('/')[-1]\n",
    "    tournement_links[year] = []\n",
    "    source = urllib.request.urlopen(link).read()\n",
    "    soup = BeautifulSoup(source,'lxml')\n",
    "    table_titles = soup.findAll(\"section\", {\"class\" : \"ResponsiveTable\"})\n",
    "    # Find the completed tournements table\n",
    "    for table in table_titles:\n",
    "        title = table.find(\"div\", {\"class\" : \"Table__Title\"})\n",
    "        if title.text == \"Completed Tournaments\":\n",
    "            # This is the one that we want\n",
    "            # Still saved in table\n",
    "            break\n",
    "    links = table.findAll('a', {'class' : \"AnchorLink\"})\n",
    "    # get all tournements in the table\n",
    "    for link in links: \n",
    "        href = link.attrs['href']\n",
    "        if \"player\" not in href.split('/'):\n",
    "            tournement_links[year].append(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse tournement results\n",
    "This saves the table from each tournmemnt in a pandas dataframe and saves\n",
    "it to a csv file in the data folder. The data folder has folder for each\n",
    "year which contains a the csv file for each tournement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tournement_results(link):\n",
    "    source = urllib.request.urlopen(link).read()\n",
    "    soup = BeautifulSoup(source,'lxml')\n",
    "    \n",
    "    compet_table = soup.find(\"div\", {\"class\" : \"competitors\"})\n",
    "    tables = compet_table.find_all(\"section\", {\"class\" : \"ResponsiveTable\"})\n",
    "    for table in tables:\n",
    "        #Get headings\n",
    "        headings = []\n",
    "        headings_tag = table.find('thead')\n",
    "        head_cells = headings_tag.findAll(\"th\")\n",
    "        if len(head_cells) < 8: \n",
    "            continue\n",
    "\n",
    "        for heading in headings_tag.findAll(\"th\"):\n",
    "                headings.append(heading.find('a').text)\n",
    "        \n",
    "        body = table.find(\"tbody\")\n",
    "        rows = body.findAll('tr')\n",
    "        player_data = []\n",
    "        for row in rows:\n",
    "            current_row = []\n",
    "            for text in row.findAll(\"td\"):\n",
    "                current_row.append(text.text)\n",
    "\n",
    "            player_data.append(current_row)\n",
    "        return [headings] + player_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "failed_links = []\n",
    "for year in tournement_links:\n",
    "    for link in tournement_links[year]:\n",
    "        data[year] = []\n",
    "        try:\n",
    "            results = get_tournement_results(link)\n",
    "\n",
    "            df = pd.DataFrame(results[1:], columns=results[0]).set_index(\"PLAYER\") \n",
    "            df[['R1', 'R2', 'R3', 'R4']] = df[['R1', 'R2', 'R3', 'R4']].replace(\"--\", np.nan).astype(float)\n",
    "            \n",
    "            df.to_csv('data/' + str(year) + '/' + link.split('=')[-1])\n",
    "            data[year].append(df)\n",
    "\n",
    "        except Exception as err: \n",
    "            failed_links.append(link)\n",
    "            print(link)\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
